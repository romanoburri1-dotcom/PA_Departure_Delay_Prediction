{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2b21355",
   "metadata": {},
   "source": [
    "Features_df importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a4e903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "features_df = pd.read_pickle(\"../data/processed/features.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d2758f",
   "metadata": {},
   "source": [
    "X definieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbe1636",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = features_df[['month_sin',\n",
    "                 'month_cos',\n",
    "                 'day_of_week_sin',\n",
    "                 'day_of_week_cos',\n",
    "                 'minute_of_day_sin',\n",
    "                 'minute_of_day_cos',\n",
    "                'wind_speed_kt',\n",
    "                'vis_category',\n",
    "                'temperature_c',\n",
    "                'spread_c',\n",
    "                'qnh_hpa',\n",
    "                'scheduled_departures',\n",
    "                'scheduled_arrivals',\n",
    "                'avg_dep_delay_prev_slot_minutes',\n",
    "                'avg_dep_delay_past_6h_minutes',\n",
    "                'scheduled_C',\n",
    "                'scheduled_D',\n",
    "                'scheduled_rwy_concept',\n",
    "                'arr_dep_ratio',\n",
    "        ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f0b66a",
   "metadata": {},
   "source": [
    "Y definieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b343ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = features_df[['avg_dep_delay_slot_minutes']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212f207d",
   "metadata": {},
   "source": [
    "XGBoost und train_test_split importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcdd461",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa03f98",
   "metadata": {},
   "source": [
    "Daten in Trainings-, Validations- und Testset aufteilen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b417c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(X,y,test_size=0.4,random_state=42,shuffle=False)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_temp,y_temp,test_size=0.5,random_state=42,shuffle=False) \n",
    "\n",
    "'''\n",
    "Daten werden aufgesplittet:\n",
    "- 60% Training\n",
    "- 20% Validierung\n",
    "- 20% Test\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77eb8485",
   "metadata": {},
   "source": [
    "XGBRegressor importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1214fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972e5ad6",
   "metadata": {},
   "source": [
    "Hyperparamter-Tuning mit RandomizedSearchCV anhand vom Trainingsset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b18044",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "param_grid = {\n",
    "    \"max_depth\": [4, 6, 8, 10],\n",
    "    \"min_child_weight\": [1, 3, 5],\n",
    "    \"subsample\": [0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.8, 1.0],\n",
    "    \"gamma\": [0, 1, 2],\n",
    "    \"reg_alpha\": [0, 0.1, 0.5],\n",
    "    \"reg_lambda\": [1, 2, 5],\n",
    "    \"learning_rate\": [0.05, 0.1],\n",
    "    \"n_estimators\": [3000]\n",
    "}\n",
    "\n",
    "model = XGBRegressor(\n",
    "    objective = 'reg:squarederror',\n",
    "    enable_categorical = True,\n",
    "    random_state = 42,\n",
    "    early_stopping_rounds = 50,\n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=4, gap=4*24)\n",
    "\n",
    "\n",
    "#You have 30-minute slots → 48 slots = 1 day\n",
    "\n",
    "#Use TimeSeriesSplit to respect time order\n",
    "\n",
    "#Optionally leave a gap (e.g. 2–3 days) to avoid leakage\n",
    "\n",
    "#Perfect for tuning, since it checks the model across multiple time periods\n",
    "\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    model,\n",
    "    param_distributions=param_grid,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=tscv,\n",
    "    n_iter=20,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "search.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=0)\n",
    "print(search.best_params_)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e733022",
   "metadata": {},
   "source": [
    "Optimierte Hyperparameter ins Modell einfügen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b3e8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    enable_categorical=True,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    early_stopping_rounds=50,\n",
    "    subsample=0.8,\n",
    "    reg_lambda=5,\n",
    "    reg_alpha=0.5,\n",
    "    n_estimators=3000,\n",
    "    min_child_weight=3,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.05,\n",
    "    gamma=1,\n",
    "    colsample_bytree=0.8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c2ecc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train,y_train,eval_set=[(X_val,y_val)],verbose=0)\n",
    "\n",
    "''' \n",
    "Modell aufgrund der Trainingsdaten trainieren.\n",
    "Nach jeder Iteration wird überprüft, wie sich das Modell auf dem Validationsset verhält.\n",
    "Wenn sich der Fehler auf dem Validationset für 50 Iterationen in Folge nicht verbessert, wird das Training abgebrochen (early stopping).\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4268115",
   "metadata": {},
   "source": [
    "Funktion erstellen, die alle Features schrittweise entfernt und jeweils ausgibt, wie sich MAE, RMSE, R^2 verhalten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d2de4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def evaluate_model(X_tr, y_tr, X_va, y_va, base_model):\n",
    "    m = clone(base_model)                      # fresh model each run\n",
    "    y_tr = y_tr.values.ravel()\n",
    "    y_va = y_va.values.ravel()\n",
    "\n",
    "    m.fit(X_tr, y_tr, eval_set=[(X_va, y_va)], verbose=False)\n",
    "\n",
    "    # ensure we predict with the best number of trees\n",
    "    if getattr(m, \"best_iteration\", None) is not None:\n",
    "        y_hat = m.predict(X_va, iteration_range=(0, m.best_iteration + 1))\n",
    "    else:\n",
    "        y_hat = m.predict(X_va)\n",
    "\n",
    "    mae  = mean_absolute_error(y_va, y_hat)\n",
    "    rmse = np.sqrt(mean_squared_error(y_va, y_hat))\n",
    "    r2   = r2_score(y_va, y_hat)\n",
    "    return mae, rmse, r2, m\n",
    "\n",
    "results = []\n",
    "\n",
    "# Baseline\n",
    "mae, rmse, r2, _ = evaluate_model(X_train, y_train, X_val, y_val, model)\n",
    "results.append({\"Feature_removed\": \"None\", \"MAE\": mae, \"RMSE\": rmse, \"R2\": r2})\n",
    "\n",
    "# One-by-one feature removal\n",
    "for col in X_train.columns:\n",
    "    X_train_red = X_train.drop(columns=[col])\n",
    "    X_val_red   = X_val.drop(columns=[col])\n",
    "    \n",
    "    mae, rmse, r2, _ = evaluate_model(X_train_red, y_train, X_val_red, y_val, model)\n",
    "    results.append({\"Feature_removed\": col, \"MAE\": mae, \"RMSE\": rmse, \"R2\": r2})\n",
    "\n",
    "# Export\n",
    "results_df = pd.DataFrame(results).sort_values(by=\"RMSE\")\n",
    "results_df.to_excel(\"feature_ablation_results_auto.xlsx\", index=False)\n",
    "print(\"Saved to feature_ablation_results_auto.xlsx\")\n",
    "\n",
    "def backward_elimination(X_train, y_train, X_val, y_val, base_model, cols, tol=0.0):\n",
    "    selected = cols.copy()\n",
    "    # baseline on all\n",
    "    mae, rmse, r2, _ = evaluate_model(X_train[selected], y_train, X_val[selected], y_val, base_model)\n",
    "    best_rmse = rmse\n",
    "    history = [{\"MAE\": mae, \"RMSE\": rmse, \"R2\": r2, \"kept\": tuple(selected), \"n_features\": len(selected)}]\n",
    "\n",
    "    while len(selected) > 1:\n",
    "        best_drop, best_metrics = None, None\n",
    "        for c in selected:\n",
    "            sub = [x for x in selected if x != c]\n",
    "            mae, rmse, r2, _ = evaluate_model(X_train[sub], y_train, X_val[sub], y_val, base_model)\n",
    "            # pick removal that most reduces RMSE\n",
    "            if rmse < (best_metrics[\"RMSE\"] if best_metrics else float(\"inf\")):\n",
    "                best_drop, best_metrics = c, {\"MAE\": mae, \"RMSE\": rmse, \"R2\": r2, \"kept\": tuple(sub)}\n",
    "        if best_metrics[\"RMSE\"] < best_rmse - tol:\n",
    "            selected.remove(best_drop)\n",
    "            best_rmse = best_metrics[\"RMSE\"]\n",
    "            history.append(best_metrics | {\"n_features\": len(selected)})\n",
    "        else:\n",
    "            break\n",
    "    return pd.DataFrame(history), selected\n",
    "\n",
    "bwd_hist, bwd_selected = backward_elimination(X_train, y_train, X_val, y_val, model, list(X_train.columns), tol=0.0)\n",
    "bwd_hist.to_excel(\"feature_subsets_backward.xlsx\", index=False)\n",
    "print(\"Backward selected:\", bwd_selected)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4caea3e1",
   "metadata": {},
   "source": [
    "Statistische Tests importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9faff440",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16b8750",
   "metadata": {},
   "source": [
    "Trainiertes Modell am Validation-Set anwenden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadbf432",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_val = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f854812",
   "metadata": {},
   "source": [
    "Mean Absolute Error (MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857f361d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_y_val = mean_absolute_error(y_val,y_pred_val)\n",
    "print(\"Mean Absolute Error (MAE) on Validation Set:\", mae_y_val, \"minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc199ad8",
   "metadata": {},
   "source": [
    "Root Mean Square Error (RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe77649d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_y_val = root_mean_squared_error(y_val,y_pred_val)\n",
    "print(\"Root Mean Square Error (RMSE) on Validation Set:\", rmse_y_val, \"minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c92226a",
   "metadata": {},
   "source": [
    "R^2 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3691f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_y_val = r2_score(y_val,y_pred_val)\n",
    "print(\"R^2 Score on Validation Set:\", r2_y_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1082f4f7",
   "metadata": {},
   "source": [
    "Scores als CSV abspeichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd5f4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_scores_v3 = {\n",
    "    \"MAE\": mae_y_val,\n",
    "    \"RMSE\": rmse_y_val,\n",
    "    \"R^2\": r2_y_val\n",
    "}\n",
    "print(baseline_scores_v3)\n",
    "#baseline_df = pd.DataFrame([baseline_scores_v3])\n",
    "#baseline_df.to_csv(\"../data/processed/baseline_model_scores_v1.5.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e73a79a",
   "metadata": {},
   "source": [
    "Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e6fdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure y is 1-D\n",
    "y_val_1d = y_val.values.ravel()  # if y_val is a 1-col DataFrame\n",
    "\n",
    "r = permutation_importance(\n",
    "    model, X_val, y_val_1d,\n",
    "    n_jobs=-1,\n",
    "    n_repeats=100,\n",
    "    random_state=42,\n",
    "    scoring=\"neg_root_mean_squared_error\"\n",
    ")\n",
    "\n",
    "# Build Series so indices align with feature names\n",
    "imp_mean = pd.Series(r.importances_mean, index=X_val.columns).sort_values(ascending=False)\n",
    "imp_std  = pd.Series(r.importances_std,  index=X_val.columns).reindex(imp_mean.index)\n",
    "\n",
    "plt.figure(figsize=(8,10))\n",
    "imp_mean.head(20).plot(\n",
    "    kind=\"barh\",\n",
    "    xerr=imp_std.head(20).values  # pass values to xerr\n",
    ")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xlabel(\"ΔRMSE [minutes]\")\n",
    "plt.title(\"Permutation-Based Feature Importance for Validation set\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa26793",
   "metadata": {},
   "source": [
    "Predicted vs Actual Delays Validaiton Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b176e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure Series alignment\n",
    "y_true = y_val.squeeze()     # actual delays\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(y_true, y_pred, alpha=0.3, edgecolor='none')\n",
    "plt.xlabel(\"Actual Delay (minutes)\")\n",
    "plt.ylabel(\"Predicted Delay (minutes)\")\n",
    "plt.title(\"Predicted vs Actual Delays (Validation Set)\")\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.xlim(-50, 200)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec50af5e",
   "metadata": {},
   "source": [
    "Residual Distribution (Residuals vs Predicted Delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24f1209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted and actual values\n",
    "y_true = y_val.squeeze()\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "# Residuals\n",
    "residuals = y_true - y_pred\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.scatter(y_pred, residuals, alpha=0.3, edgecolor='none')\n",
    "plt.axhline(0, color=\"red\", linestyle=\"--\", lw=2)\n",
    "plt.title(\"Residuals vs Predicted Delay (Validation Set)\")\n",
    "plt.xlabel(\"Predicted Delay [minutes]\")\n",
    "plt.ylabel(\"Residual (Actual - Predicted), [minutes]\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7bdb65",
   "metadata": {},
   "source": [
    "Residual Distribution (Residuals vs Actual Delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382afae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Make y_val a 1-D Series\n",
    "y_true = y_val.squeeze()            # or: y_val.iloc[:, 0]\n",
    "\n",
    "# 2) Make predictions and wrap in a Series with the same index\n",
    "y_pred = pd.Series(model.predict(X_val), index=y_true.index)\n",
    "\n",
    "# 3) Residuals\n",
    "residuals = y_true - y_pred\n",
    "\n",
    "# 4) Residuals vs ACTUAL plot\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.scatter(y_true, residuals, alpha=0.3, edgecolor='none')\n",
    "plt.axhline(0, color=\"red\", linestyle=\"--\", lw=2)\n",
    "plt.title(\"Residuals vs Actual Delay (Validation Set)\")\n",
    "plt.xlabel(\"Actual Delay (minutes)\")\n",
    "plt.ylabel(\"Residual (Actual - Predicted, minutes)\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
